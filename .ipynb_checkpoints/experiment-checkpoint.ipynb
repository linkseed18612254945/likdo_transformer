{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers.trainer import TrainingArguments, Trainer\n",
    "import logging\n",
    "from utils import metrics\n",
    "import datasets\n",
    "import mlflow\n",
    "from utils import container, text_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://10.10.111.130:5005\")\n",
    "mlflow.set_experiment(\"bert_classify_finetune_experiment\")\n",
    "\n",
    "mlflow_tags = {\n",
    "    \"paper\": \"How to Fine-Tune BERT for Text Classification\",\n",
    "    \"dl_frame\": \"huggingface-pytorch\",\n",
    "    \"mlflow.runName\": \"bert_imdb_baseline_v2\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Build pre-trained model bert-google-uncase-base\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model_name = 'bert-google-uncase-base'\n",
    "logger.critical(\"Build pre-trained model {}\".format(pre_trained_model_name))\n",
    "base_pre_trained_model_path = '/home/ubuntu/likun/nlp_pretrained/{}'.format(pre_trained_model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_pre_trained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Build Training and validating dataset\n",
      "Reusing dataset imdb (/home/ubuntu/likun/huggingface_dataset/imdb/plain_text/1.0.0/90099cb476936b753383ba2ae6ab2eae419b2e87f71cd5189cb9c8e5814d12a3)\n"
     ]
    }
   ],
   "source": [
    "logger.critical(\"Build Training and validating dataset\")\n",
    "dataset_args = {\n",
    "    \"name\": \"imdb\",\n",
    "    \"data_cache_dir\": f\"/home/ubuntu/likun/huggingface_dataset\",\n",
    "    \"train_size\": 25000,\n",
    "    \"val_size\": 0,\n",
    "    \"test_size\": 25000,\n",
    "    \"max_length\": 510\n",
    "}\n",
    "mlflow_tags.update(dataset_args)\n",
    "dataset = datasets.load_dataset(dataset_args['name'], cache_dir=dataset_args['data_cache_dir'])\n",
    "\n",
    "# num_labels = dataset['train'].features['label-coarse'].num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    unsupervised: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n",
      "{'text': Value(dtype='string', id=None), 'label': ClassLabel(num_classes=2, names=['neg', 'pos'], names_file=None, id=None)}\n",
      "train size 25000\n",
      "Train dataset stat:\n",
      "Min length: 52, Max length: 13704, Avg length: 1325.06964\n",
      "test size 25000\n",
      "Test dataset stat:\n",
      "Min length: 32, Max length: 12988, Avg length: 1293.7924\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(dataset['train'].features)\n",
    "print('train size {}'.format(len(dataset['train'])))\n",
    "\n",
    "print('Train dataset stat:')\n",
    "text_utils.text_stat([example['text'] for example in dataset['train']])\n",
    "dataset['train'][1]\n",
    "\n",
    "print('test size {}'.format(len(dataset['test'])))\n",
    "print('Test dataset stat:')\n",
    "text_utils.text_stat([example['text'] for example in dataset['test']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.map(lambda example: {'label': example['label-coarse']}, remove_columns=['label-coarse', 'label-fine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_args['train_size'] == len(dataset['train']):\n",
    "    train_dataset = dataset['train']\n",
    "elif dataset_args['val_size'] != 0:\n",
    "    train_dataset = dataset['train'].train_test_split(train_size=dataset_args['train_size'],\n",
    "                                                      test_size=dataset_args['val_size'])\n",
    "    train_dataset, val_dataset = train_dataset['train'], train_dataset['test']\n",
    "else:\n",
    "    train_dataset = dataset['train'].train_test_split(train_size=dataset_args['train_size'],\n",
    "                                                      test_size=1)\n",
    "    train_dataset, _ = train_dataset['train'], train_dataset['test']\n",
    "\n",
    "if dataset_args['test_size'] < len(dataset['test']):\n",
    "    test_dataset = dataset['test'].train_test_split(train_size=dataset_args['test_size'])\n",
    "    test_dataset = test_dataset['train']\n",
    "else:\n",
    "    test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_tail_encode(examples):\n",
    "    examples['text'] = list(map(lambda t: t[:128] + t[-382:] if len(t) > 510 else t,examples['text']))\n",
    "    return tokenizer(examples['text'] , max_length=dataset_args['max_length'], truncation=True, padding='max_length')\n",
    "\n",
    "def standard_encode(examples):\n",
    "    return tokenizer(examples['text'] , max_length=dataset_args['max_length'], truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b0f98b7c5d4596b8917d458f3ed00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f12442383fe4e95a375e648a3b88868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encode_func = head_tail_encode\n",
    "train_dataset = train_dataset.map(encode_func, batched=True)\n",
    "test_dataset = test_dataset.map(encode_func, batched=True)\n",
    "if dataset_args['val_size'] != 0:\n",
    "    val_dataset = val_dataset.map(encode_func, batched=True)\n",
    "else:\n",
    "    val_dataset = test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setup the training environment\n",
      "Some weights of the model checkpoint at /home/ubuntu/likun/nlp_pretrained/bert-google-uncase-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/ubuntu/likun/nlp_pretrained/bert-google-uncase-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "logger.critical(\"Setup the training environment\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(base_pre_trained_model_path,\n",
    "                                                           num_labels=num_labels,\n",
    "                                                           output_attentions=False,\n",
    "                                                           output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 8\n",
    "warmup_steps = int(len(train_dataset) // train_batch_size * 0.1)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='/home/ubuntu/likun/nlp_save_kernels/{}'.format(mlflow_tags['mlflow.runName']),  # output directory\n",
    "    num_train_epochs=4,  # total number of training epochs\n",
    "    per_device_train_batch_size=train_batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=32,  # batch size for evaluation\n",
    "    warmup_steps=warmup_steps,  # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.95,  # strength of weight decay\n",
    "    logging_dir='/home/ubuntu/likun/nlp_training_logs/{}'.format(mlflow_tags['mlflow.runName']),  # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-5,\n",
    "    seed=44,\n",
    "    no_cuda=False,\n",
    "    evaluate_during_training=True\n",
    ")\n",
    "train_params = {k: v for k, v in training_args.__dict__.items() if (isinstance(v, int) or isinstance(v, float)) and not isinstance(v, bool)}\n",
    "trainer = Trainer(\n",
    "    model=model,  # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,  # training arguments, defined above\n",
    "    train_dataset=train_dataset,  # training dataset\n",
    "    eval_dataset=val_dataset,  # evaluation dataset\n",
    "    compute_metrics=metrics.classify_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start to train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913787a56f2b4d58bea210155318a530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2bc69db493420e8de9d3c20315338f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1563.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8880080342292787, 'learning_rate': 6.41025641025641e-07, 'epoch': 0.006397952655150352, 'step': 10}\n",
      "{'loss': 1.8170116543769836, 'learning_rate': 1.282051282051282e-06, 'epoch': 0.012795905310300703, 'step': 20}\n",
      "{'loss': 1.6331066012382507, 'learning_rate': 1.9230769230769234e-06, 'epoch': 0.019193857965451054, 'step': 30}\n",
      "{'loss': 1.4644789934158324, 'learning_rate': 2.564102564102564e-06, 'epoch': 0.025591810620601407, 'step': 40}\n",
      "{'loss': 1.3486561179161072, 'learning_rate': 3.205128205128206e-06, 'epoch': 0.03198976327575176, 'step': 50}\n",
      "{'loss': 1.2790204882621765, 'learning_rate': 3.846153846153847e-06, 'epoch': 0.03838771593090211, 'step': 60}\n",
      "{'loss': 1.1935676336288452, 'learning_rate': 4.487179487179488e-06, 'epoch': 0.044785668586052464, 'step': 70}\n",
      "{'loss': 1.1019884467124939, 'learning_rate': 5.128205128205128e-06, 'epoch': 0.05118362124120281, 'step': 80}\n",
      "{'loss': 1.0263014137744904, 'learning_rate': 5.769230769230769e-06, 'epoch': 0.05758157389635317, 'step': 90}\n",
      "{'loss': 0.9473634600639343, 'learning_rate': 6.410256410256412e-06, 'epoch': 0.06397952655150352, 'step': 100}\n",
      "{'loss': 0.8779588878154755, 'learning_rate': 7.051282051282053e-06, 'epoch': 0.07037747920665387, 'step': 110}\n",
      "{'loss': 0.8152702271938324, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.07677543186180422, 'step': 120}\n",
      "{'loss': 0.7611246705055237, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.08317338451695458, 'step': 130}\n",
      "{'loss': 0.729987382888794, 'learning_rate': 8.974358974358976e-06, 'epoch': 0.08957133717210493, 'step': 140}\n",
      "{'loss': 0.6622770130634308, 'learning_rate': 9.615384615384616e-06, 'epoch': 0.09596928982725528, 'step': 150}\n",
      "{'loss': 0.645617789030075, 'learning_rate': 1.0256410256410256e-05, 'epoch': 0.10236724248240563, 'step': 160}\n",
      "{'loss': 0.5804870873689651, 'learning_rate': 1.0897435897435898e-05, 'epoch': 0.10876519513755598, 'step': 170}\n",
      "{'loss': 0.5375954955816269, 'learning_rate': 1.1538461538461538e-05, 'epoch': 0.11516314779270634, 'step': 180}\n",
      "{'loss': 0.4942117780447006, 'learning_rate': 1.217948717948718e-05, 'epoch': 0.12156110044785669, 'step': 190}\n",
      "{'loss': 0.502008906006813, 'learning_rate': 1.2820512820512823e-05, 'epoch': 0.12795905310300704, 'step': 200}\n",
      "{'loss': 0.6032879412174225, 'learning_rate': 1.3461538461538463e-05, 'epoch': 0.1343570057581574, 'step': 210}\n",
      "{'loss': 0.44748263657093046, 'learning_rate': 1.4102564102564105e-05, 'epoch': 0.14075495841330773, 'step': 220}\n",
      "{'loss': 0.40722405910491943, 'learning_rate': 1.4743589743589745e-05, 'epoch': 0.1471529110684581, 'step': 230}\n",
      "{'loss': 0.3994180724024773, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.15355086372360843, 'step': 240}\n",
      "{'loss': 0.37950132191181185, 'learning_rate': 1.602564102564103e-05, 'epoch': 0.1599488163787588, 'step': 250}\n",
      "{'loss': 0.3253300651907921, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.16634676903390916, 'step': 260}\n",
      "{'loss': 0.446299335360527, 'learning_rate': 1.730769230769231e-05, 'epoch': 0.1727447216890595, 'step': 270}\n",
      "{'loss': 0.37876517325639725, 'learning_rate': 1.794871794871795e-05, 'epoch': 0.17914267434420986, 'step': 280}\n",
      "{'loss': 0.40295732766389847, 'learning_rate': 1.8589743589743593e-05, 'epoch': 0.1855406269993602, 'step': 290}\n",
      "{'loss': 0.296490515768528, 'learning_rate': 1.923076923076923e-05, 'epoch': 0.19193857965451055, 'step': 300}\n",
      "{'loss': 0.48192178606987, 'learning_rate': 1.9871794871794873e-05, 'epoch': 0.19833653230966092, 'step': 310}\n",
      "{'loss': 0.37269202917814254, 'learning_rate': 1.9973063973063975e-05, 'epoch': 0.20473448496481125, 'step': 320}\n",
      "{'loss': 0.38345871269702914, 'learning_rate': 1.993939393939394e-05, 'epoch': 0.21113243761996162, 'step': 330}\n",
      "{'loss': 0.31456885784864425, 'learning_rate': 1.990572390572391e-05, 'epoch': 0.21753039027511195, 'step': 340}\n",
      "{'loss': 0.4491924703121185, 'learning_rate': 1.9872053872053874e-05, 'epoch': 0.22392834293026231, 'step': 350}\n",
      "{'loss': 0.41831305623054504, 'learning_rate': 1.983838383838384e-05, 'epoch': 0.23032629558541268, 'step': 360}\n",
      "{'loss': 0.28264402598142624, 'learning_rate': 1.9804713804713808e-05, 'epoch': 0.236724248240563, 'step': 370}\n",
      "{'loss': 0.434664323925972, 'learning_rate': 1.9771043771043774e-05, 'epoch': 0.24312220089571338, 'step': 380}\n",
      "{'loss': 0.3645030215382576, 'learning_rate': 1.973737373737374e-05, 'epoch': 0.2495201535508637, 'step': 390}\n",
      "{'loss': 0.3229972258210182, 'learning_rate': 1.9703703703703704e-05, 'epoch': 0.2559181062060141, 'step': 400}\n",
      "{'loss': 0.31950969696044923, 'learning_rate': 1.9670033670033673e-05, 'epoch': 0.26231605886116444, 'step': 410}\n",
      "{'loss': 0.36258170008659363, 'learning_rate': 1.963636363636364e-05, 'epoch': 0.2687140115163148, 'step': 420}\n",
      "{'loss': 0.35900367200374605, 'learning_rate': 1.9602693602693604e-05, 'epoch': 0.2751119641714651, 'step': 430}\n",
      "{'loss': 0.2581558614969254, 'learning_rate': 1.956902356902357e-05, 'epoch': 0.28150991682661547, 'step': 440}\n",
      "{'loss': 0.3487930163741112, 'learning_rate': 1.9535353535353534e-05, 'epoch': 0.28790786948176583, 'step': 450}\n",
      "{'loss': 0.3672671943902969, 'learning_rate': 1.9501683501683503e-05, 'epoch': 0.2943058221369162, 'step': 460}\n",
      "{'loss': 0.29950702041387556, 'learning_rate': 1.946801346801347e-05, 'epoch': 0.30070377479206656, 'step': 470}\n",
      "{'loss': 0.316200889647007, 'learning_rate': 1.9434343434343437e-05, 'epoch': 0.30710172744721687, 'step': 480}\n",
      "{'loss': 0.23191844671964645, 'learning_rate': 1.9400673400673403e-05, 'epoch': 0.31349968010236723, 'step': 490}\n",
      "{'loss': 0.3596245065331459, 'learning_rate': 1.9367003367003368e-05, 'epoch': 0.3198976327575176, 'step': 500}\n",
      "{'loss': 0.3071062847971916, 'learning_rate': 1.9333333333333333e-05, 'epoch': 0.32629558541266795, 'step': 510}\n",
      "{'loss': 0.238428895175457, 'learning_rate': 1.92996632996633e-05, 'epoch': 0.3326935380678183, 'step': 520}\n",
      "{'loss': 0.34784126579761504, 'learning_rate': 1.9265993265993268e-05, 'epoch': 0.3390914907229686, 'step': 530}\n",
      "{'loss': 0.396059550344944, 'learning_rate': 1.9232323232323233e-05, 'epoch': 0.345489443378119, 'step': 540}\n",
      "{'loss': 0.3402764737606049, 'learning_rate': 1.91986531986532e-05, 'epoch': 0.35188739603326935, 'step': 550}\n",
      "{'loss': 0.2969706028699875, 'learning_rate': 1.9164983164983167e-05, 'epoch': 0.3582853486884197, 'step': 560}\n",
      "{'loss': 0.22518176287412645, 'learning_rate': 1.9131313131313132e-05, 'epoch': 0.3646833013435701, 'step': 570}\n",
      "{'loss': 0.30020176619291306, 'learning_rate': 1.9097643097643098e-05, 'epoch': 0.3710812539987204, 'step': 580}\n",
      "{'loss': 0.28256802558898925, 'learning_rate': 1.9063973063973063e-05, 'epoch': 0.37747920665387075, 'step': 590}\n",
      "{'loss': 0.321318618953228, 'learning_rate': 1.9030303030303032e-05, 'epoch': 0.3838771593090211, 'step': 600}\n",
      "{'loss': 0.2110513687133789, 'learning_rate': 1.8996632996632997e-05, 'epoch': 0.3902751119641715, 'step': 610}\n",
      "{'loss': 0.2882276922464371, 'learning_rate': 1.8962962962962966e-05, 'epoch': 0.39667306461932184, 'step': 620}\n",
      "{'loss': 0.2699605628848076, 'learning_rate': 1.892929292929293e-05, 'epoch': 0.40307101727447214, 'step': 630}\n",
      "{'loss': 0.27588396817445754, 'learning_rate': 1.8895622895622897e-05, 'epoch': 0.4094689699296225, 'step': 640}\n",
      "{'loss': 0.34707618653774264, 'learning_rate': 1.8861952861952862e-05, 'epoch': 0.41586692258477287, 'step': 650}\n",
      "{'loss': 0.2935134157538414, 'learning_rate': 1.8828282828282827e-05, 'epoch': 0.42226487523992323, 'step': 660}\n",
      "{'loss': 0.25309918373823165, 'learning_rate': 1.8794612794612796e-05, 'epoch': 0.4286628278950736, 'step': 670}\n",
      "{'loss': 0.2811908543109894, 'learning_rate': 1.876094276094276e-05, 'epoch': 0.4350607805502239, 'step': 680}\n",
      "{'loss': 0.3254506304860115, 'learning_rate': 1.872727272727273e-05, 'epoch': 0.44145873320537427, 'step': 690}\n",
      "{'loss': 0.2348922610282898, 'learning_rate': 1.8693602693602696e-05, 'epoch': 0.44785668586052463, 'step': 700}\n",
      "{'loss': 0.1976177915930748, 'learning_rate': 1.865993265993266e-05, 'epoch': 0.454254638515675, 'step': 710}\n",
      "{'loss': 0.262847526371479, 'learning_rate': 1.8626262626262626e-05, 'epoch': 0.46065259117082535, 'step': 720}\n",
      "{'loss': 0.33105459064245224, 'learning_rate': 1.8592592592592592e-05, 'epoch': 0.46705054382597566, 'step': 730}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.26144900023937223, 'learning_rate': 1.855892255892256e-05, 'epoch': 0.473448496481126, 'step': 740}\n",
      "{'loss': 0.22176869660615922, 'learning_rate': 1.8525252525252526e-05, 'epoch': 0.4798464491362764, 'step': 750}\n",
      "{'loss': 0.3019829779863358, 'learning_rate': 1.8491582491582495e-05, 'epoch': 0.48624440179142675, 'step': 760}\n",
      "{'loss': 0.29297216087579725, 'learning_rate': 1.845791245791246e-05, 'epoch': 0.4926423544465771, 'step': 770}\n",
      "{'loss': 0.1666583776473999, 'learning_rate': 1.8424242424242425e-05, 'epoch': 0.4990403071017274, 'step': 780}\n",
      "{'loss': 0.335477802157402, 'learning_rate': 1.839057239057239e-05, 'epoch': 0.5054382597568778, 'step': 790}\n",
      "{'loss': 0.34468733668327334, 'learning_rate': 1.8356902356902356e-05, 'epoch': 0.5118362124120281, 'step': 800}\n",
      "{'loss': 0.28547153025865557, 'learning_rate': 1.8323232323232325e-05, 'epoch': 0.5182341650671785, 'step': 810}\n",
      "{'loss': 0.26273577064275744, 'learning_rate': 1.828956228956229e-05, 'epoch': 0.5246321177223289, 'step': 820}\n",
      "{'loss': 0.20414567738771439, 'learning_rate': 1.825589225589226e-05, 'epoch': 0.5310300703774792, 'step': 830}\n",
      "{'loss': 0.2987376779317856, 'learning_rate': 1.8222222222222224e-05, 'epoch': 0.5374280230326296, 'step': 840}\n",
      "{'loss': 0.3294157788157463, 'learning_rate': 1.818855218855219e-05, 'epoch': 0.5438259756877799, 'step': 850}\n",
      "{'loss': 0.30214416682720185, 'learning_rate': 1.8154882154882155e-05, 'epoch': 0.5502239283429302, 'step': 860}\n",
      "{'loss': 0.26997891068458557, 'learning_rate': 1.812121212121212e-05, 'epoch': 0.5566218809980806, 'step': 870}\n",
      "{'loss': 0.2676362574100494, 'learning_rate': 1.808754208754209e-05, 'epoch': 0.5630198336532309, 'step': 880}\n",
      "{'loss': 0.4166804879903793, 'learning_rate': 1.8053872053872055e-05, 'epoch': 0.5694177863083814, 'step': 890}\n",
      "{'loss': 0.3029683634638786, 'learning_rate': 1.8020202020202023e-05, 'epoch': 0.5758157389635317, 'step': 900}\n",
      "{'loss': 0.24160717725753783, 'learning_rate': 1.798653198653199e-05, 'epoch': 0.582213691618682, 'step': 910}\n",
      "{'loss': 0.3123813048005104, 'learning_rate': 1.7952861952861954e-05, 'epoch': 0.5886116442738324, 'step': 920}\n",
      "{'loss': 0.2829052895307541, 'learning_rate': 1.791919191919192e-05, 'epoch': 0.5950095969289827, 'step': 930}\n",
      "{'loss': 0.210512974858284, 'learning_rate': 1.7885521885521885e-05, 'epoch': 0.6014075495841331, 'step': 940}\n",
      "{'loss': 0.3133713588118553, 'learning_rate': 1.7851851851851853e-05, 'epoch': 0.6078055022392834, 'step': 950}\n",
      "{'loss': 0.3208182126283646, 'learning_rate': 1.781818181818182e-05, 'epoch': 0.6142034548944337, 'step': 960}\n",
      "{'loss': 0.18280184417963027, 'learning_rate': 1.7784511784511788e-05, 'epoch': 0.6206014075495841, 'step': 970}\n",
      "{'loss': 0.29237087070941925, 'learning_rate': 1.7750841750841753e-05, 'epoch': 0.6269993602047345, 'step': 980}\n",
      "{'loss': 0.26445699483156204, 'learning_rate': 1.771717171717172e-05, 'epoch': 0.6333973128598849, 'step': 990}\n",
      "{'loss': 0.23758012503385545, 'learning_rate': 1.7683501683501684e-05, 'epoch': 0.6397952655150352, 'step': 1000}\n",
      "{'loss': 0.2968298330903053, 'learning_rate': 1.764983164983165e-05, 'epoch': 0.6461932181701855, 'step': 1010}\n",
      "{'loss': 0.2441947191953659, 'learning_rate': 1.7616161616161618e-05, 'epoch': 0.6525911708253359, 'step': 1020}\n",
      "{'loss': 0.2915825188159943, 'learning_rate': 1.7582491582491583e-05, 'epoch': 0.6589891234804862, 'step': 1030}\n",
      "{'loss': 0.3019419401884079, 'learning_rate': 1.7548821548821552e-05, 'epoch': 0.6653870761356366, 'step': 1040}\n",
      "{'loss': 0.2496386244893074, 'learning_rate': 1.7515151515151517e-05, 'epoch': 0.6717850287907869, 'step': 1050}\n",
      "{'loss': 0.22745753824710846, 'learning_rate': 1.7481481481481483e-05, 'epoch': 0.6781829814459372, 'step': 1060}\n",
      "{'loss': 0.22978042364120482, 'learning_rate': 1.7447811447811448e-05, 'epoch': 0.6845809341010877, 'step': 1070}\n",
      "{'loss': 0.1682039752602577, 'learning_rate': 1.7414141414141413e-05, 'epoch': 0.690978886756238, 'step': 1080}\n",
      "{'loss': 0.33111471086740496, 'learning_rate': 1.7380471380471382e-05, 'epoch': 0.6973768394113884, 'step': 1090}\n",
      "{'loss': 0.2600037932395935, 'learning_rate': 1.7346801346801347e-05, 'epoch': 0.7037747920665387, 'step': 1100}\n",
      "{'loss': 0.26162800192832947, 'learning_rate': 1.7313131313131316e-05, 'epoch': 0.710172744721689, 'step': 1110}\n",
      "{'loss': 0.20710424482822418, 'learning_rate': 1.727946127946128e-05, 'epoch': 0.7165706973768394, 'step': 1120}\n",
      "{'loss': 0.23899686485528945, 'learning_rate': 1.7245791245791247e-05, 'epoch': 0.7229686500319897, 'step': 1130}\n",
      "{'loss': 0.323779858648777, 'learning_rate': 1.7212121212121212e-05, 'epoch': 0.7293666026871402, 'step': 1140}\n",
      "{'loss': 0.295722621679306, 'learning_rate': 1.717845117845118e-05, 'epoch': 0.7357645553422905, 'step': 1150}\n",
      "{'loss': 0.24071451872587205, 'learning_rate': 1.7144781144781146e-05, 'epoch': 0.7421625079974408, 'step': 1160}\n",
      "{'loss': 0.38131207823753355, 'learning_rate': 1.7111111111111112e-05, 'epoch': 0.7485604606525912, 'step': 1170}\n",
      "{'loss': 0.287678624689579, 'learning_rate': 1.707744107744108e-05, 'epoch': 0.7549584133077415, 'step': 1180}\n",
      "{'loss': 0.17649302035570144, 'learning_rate': 1.7043771043771046e-05, 'epoch': 0.7613563659628919, 'step': 1190}\n",
      "{'loss': 0.23697971254587175, 'learning_rate': 1.701010101010101e-05, 'epoch': 0.7677543186180422, 'step': 1200}\n",
      "{'loss': 0.4303207561373711, 'learning_rate': 1.6976430976430977e-05, 'epoch': 0.7741522712731925, 'step': 1210}\n",
      "{'loss': 0.20789080262184143, 'learning_rate': 1.6942760942760945e-05, 'epoch': 0.780550223928343, 'step': 1220}\n",
      "{'loss': 0.19665128141641616, 'learning_rate': 1.690909090909091e-05, 'epoch': 0.7869481765834933, 'step': 1230}\n",
      "{'loss': 0.20957956463098526, 'learning_rate': 1.6875420875420876e-05, 'epoch': 0.7933461292386437, 'step': 1240}\n",
      "{'loss': 0.3634605586528778, 'learning_rate': 1.6841750841750845e-05, 'epoch': 0.799744081893794, 'step': 1250}\n",
      "{'loss': 0.21916854232549668, 'learning_rate': 1.680808080808081e-05, 'epoch': 0.8061420345489443, 'step': 1260}\n",
      "{'loss': 0.2834692418575287, 'learning_rate': 1.6774410774410776e-05, 'epoch': 0.8125399872040947, 'step': 1270}\n",
      "{'loss': 0.19255654960870744, 'learning_rate': 1.674074074074074e-05, 'epoch': 0.818937939859245, 'step': 1280}\n",
      "{'loss': 0.19984110444784164, 'learning_rate': 1.670707070707071e-05, 'epoch': 0.8253358925143954, 'step': 1290}\n",
      "{'loss': 0.2805426374077797, 'learning_rate': 1.6673400673400675e-05, 'epoch': 0.8317338451695457, 'step': 1300}\n",
      "{'loss': 0.25430969446897506, 'learning_rate': 1.663973063973064e-05, 'epoch': 0.838131797824696, 'step': 1310}\n",
      "{'loss': 0.2690167486667633, 'learning_rate': 1.660606060606061e-05, 'epoch': 0.8445297504798465, 'step': 1320}\n",
      "{'loss': 0.264230078458786, 'learning_rate': 1.6572390572390575e-05, 'epoch': 0.8509277031349968, 'step': 1330}\n",
      "{'loss': 0.15505924969911575, 'learning_rate': 1.653872053872054e-05, 'epoch': 0.8573256557901472, 'step': 1340}\n",
      "{'loss': 0.2744140729308128, 'learning_rate': 1.6505050505050505e-05, 'epoch': 0.8637236084452975, 'step': 1350}\n",
      "{'loss': 0.26910738199949263, 'learning_rate': 1.6471380471380474e-05, 'epoch': 0.8701215611004478, 'step': 1360}\n",
      "{'loss': 0.3136672914028168, 'learning_rate': 1.643771043771044e-05, 'epoch': 0.8765195137555982, 'step': 1370}\n",
      "{'loss': 0.20781645476818084, 'learning_rate': 1.6404040404040405e-05, 'epoch': 0.8829174664107485, 'step': 1380}\n",
      "{'loss': 0.21911541521549224, 'learning_rate': 1.6370370370370374e-05, 'epoch': 0.889315419065899, 'step': 1390}\n",
      "{'loss': 0.36234226226806643, 'learning_rate': 1.633670033670034e-05, 'epoch': 0.8957133717210493, 'step': 1400}\n",
      "{'loss': 0.22117646783590317, 'learning_rate': 1.6303030303030304e-05, 'epoch': 0.9021113243761996, 'step': 1410}\n",
      "{'loss': 0.2630299299955368, 'learning_rate': 1.626936026936027e-05, 'epoch': 0.90850927703135, 'step': 1420}\n",
      "{'loss': 0.20641613155603408, 'learning_rate': 1.623569023569024e-05, 'epoch': 0.9149072296865003, 'step': 1430}\n",
      "{'loss': 0.26205072104930877, 'learning_rate': 1.6202020202020204e-05, 'epoch': 0.9213051823416507, 'step': 1440}\n",
      "{'loss': 0.1350156307220459, 'learning_rate': 1.616835016835017e-05, 'epoch': 0.927703134996801, 'step': 1450}\n",
      "{'loss': 0.39205626100301744, 'learning_rate': 1.6134680134680138e-05, 'epoch': 0.9341010876519513, 'step': 1460}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.24675323069095612, 'learning_rate': 1.6101010101010103e-05, 'epoch': 0.9404990403071017, 'step': 1470}\n",
      "{'loss': 0.301469224691391, 'learning_rate': 1.606734006734007e-05, 'epoch': 0.946896992962252, 'step': 1480}\n",
      "{'loss': 0.2819507151842117, 'learning_rate': 1.6033670033670034e-05, 'epoch': 0.9532949456174025, 'step': 1490}\n",
      "{'loss': 0.1753104269504547, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.9596928982725528, 'step': 1500}\n",
      "{'loss': 0.267755015194416, 'learning_rate': 1.5966329966329968e-05, 'epoch': 0.9660908509277031, 'step': 1510}\n",
      "{'loss': 0.26680568009614947, 'learning_rate': 1.5932659932659933e-05, 'epoch': 0.9724888035828535, 'step': 1520}\n",
      "{'loss': 0.3581096053123474, 'learning_rate': 1.5898989898989902e-05, 'epoch': 0.9788867562380038, 'step': 1530}\n",
      "{'loss': 0.35513498783111574, 'learning_rate': 1.5865319865319868e-05, 'epoch': 0.9852847088931542, 'step': 1540}\n",
      "{'loss': 0.2280543178319931, 'learning_rate': 1.5831649831649833e-05, 'epoch': 0.9916826615483045, 'step': 1550}\n",
      "{'loss': 0.22486635148525239, 'learning_rate': 1.5797979797979798e-05, 'epoch': 0.9980806142034548, 'step': 1560}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec893053f8a04278bf16e54b17b2eb3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1563.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.22317509055137635, 'learning_rate': 1.5764309764309767e-05, 'epoch': 1.0044785668586051, 'step': 1570}\n",
      "{'loss': 0.20434503853321076, 'learning_rate': 1.5730639730639732e-05, 'epoch': 1.0108765195137557, 'step': 1580}\n",
      "{'loss': 0.15082778483629228, 'learning_rate': 1.5696969696969698e-05, 'epoch': 1.017274472168906, 'step': 1590}\n",
      "{'loss': 0.1930029347538948, 'learning_rate': 1.5663299663299666e-05, 'epoch': 1.0236724248240563, 'step': 1600}\n",
      "{'loss': 0.20182546526193618, 'learning_rate': 1.5629629629629632e-05, 'epoch': 1.0300703774792066, 'step': 1610}\n",
      "{'loss': 0.153373883664608, 'learning_rate': 1.5595959595959597e-05, 'epoch': 1.036468330134357, 'step': 1620}\n",
      "{'loss': 0.0989776760339737, 'learning_rate': 1.5562289562289563e-05, 'epoch': 1.0428662827895074, 'step': 1630}\n",
      "{'loss': 0.13197975605726242, 'learning_rate': 1.552861952861953e-05, 'epoch': 1.0492642354446577, 'step': 1640}\n",
      "{'loss': 0.19552517384290696, 'learning_rate': 1.5494949494949497e-05, 'epoch': 1.055662188099808, 'step': 1650}\n",
      "{'loss': 0.21064443588256837, 'learning_rate': 1.5461279461279462e-05, 'epoch': 1.0620601407549584, 'step': 1660}\n",
      "{'loss': 0.05442319065332413, 'learning_rate': 1.5427609427609427e-05, 'epoch': 1.0684580934101087, 'step': 1670}\n",
      "{'loss': 0.1777867317199707, 'learning_rate': 1.5393939393939393e-05, 'epoch': 1.0748560460652592, 'step': 1680}\n",
      "{'loss': 0.1941386044025421, 'learning_rate': 1.536026936026936e-05, 'epoch': 1.0812539987204095, 'step': 1690}\n",
      "{'loss': 0.15656704157590867, 'learning_rate': 1.5326599326599327e-05, 'epoch': 1.0876519513755598, 'step': 1700}\n",
      "{'loss': 0.18322370201349258, 'learning_rate': 1.5292929292929296e-05, 'epoch': 1.0940499040307101, 'step': 1710}\n",
      "{'loss': 0.08562736958265305, 'learning_rate': 1.525925925925926e-05, 'epoch': 1.1004478566858604, 'step': 1720}\n",
      "{'loss': 0.20222516357898712, 'learning_rate': 1.5225589225589228e-05, 'epoch': 1.106845809341011, 'step': 1730}\n",
      "{'loss': 0.0879954606294632, 'learning_rate': 1.5191919191919193e-05, 'epoch': 1.1132437619961613, 'step': 1740}\n",
      "{'loss': 0.2529040902853012, 'learning_rate': 1.5158249158249159e-05, 'epoch': 1.1196417146513116, 'step': 1750}\n",
      "{'loss': 0.1514437437057495, 'learning_rate': 1.5124579124579126e-05, 'epoch': 1.1260396673064619, 'step': 1760}\n",
      "{'loss': 0.1496060773730278, 'learning_rate': 1.5090909090909091e-05, 'epoch': 1.1324376199616122, 'step': 1770}\n",
      "{'loss': 0.15311737656593322, 'learning_rate': 1.505723905723906e-05, 'epoch': 1.1388355726167627, 'step': 1780}\n",
      "{'loss': 0.09788717776536941, 'learning_rate': 1.5023569023569025e-05, 'epoch': 1.145233525271913, 'step': 1790}\n",
      "{'loss': 0.14059891551733017, 'learning_rate': 1.4989898989898992e-05, 'epoch': 1.1516314779270633, 'step': 1800}\n",
      "{'loss': 0.1594172462821007, 'learning_rate': 1.4956228956228958e-05, 'epoch': 1.1580294305822136, 'step': 1810}\n",
      "{'loss': 0.30601964741945265, 'learning_rate': 1.4922558922558923e-05, 'epoch': 1.164427383237364, 'step': 1820}\n",
      "{'loss': 0.14685822427272796, 'learning_rate': 1.488888888888889e-05, 'epoch': 1.1708253358925145, 'step': 1830}\n",
      "{'loss': 0.09043294787406922, 'learning_rate': 1.4855218855218856e-05, 'epoch': 1.1772232885476648, 'step': 1840}\n",
      "{'loss': 0.20610956996679305, 'learning_rate': 1.4821548821548824e-05, 'epoch': 1.183621241202815, 'step': 1850}\n",
      "{'loss': 0.1331712856888771, 'learning_rate': 1.478787878787879e-05, 'epoch': 1.1900191938579654, 'step': 1860}\n",
      "{'loss': 0.14121037423610688, 'learning_rate': 1.4754208754208757e-05, 'epoch': 1.1964171465131157, 'step': 1870}\n",
      "{'loss': 0.1549241989850998, 'learning_rate': 1.4720538720538722e-05, 'epoch': 1.2028150991682662, 'step': 1880}\n",
      "{'loss': 0.223551444709301, 'learning_rate': 1.4686868686868687e-05, 'epoch': 1.2092130518234165, 'step': 1890}\n",
      "{'loss': 0.1428386986255646, 'learning_rate': 1.4653198653198654e-05, 'epoch': 1.2156110044785668, 'step': 1900}\n",
      "{'loss': 0.11325210183858872, 'learning_rate': 1.461952861952862e-05, 'epoch': 1.2220089571337172, 'step': 1910}\n",
      "{'loss': 0.10207542926073074, 'learning_rate': 1.4585858585858587e-05, 'epoch': 1.2284069097888675, 'step': 1920}\n",
      "{'loss': 0.20691387355327606, 'learning_rate': 1.4552188552188552e-05, 'epoch': 1.234804862444018, 'step': 1930}\n",
      "{'loss': 0.28944556415081024, 'learning_rate': 1.4518518518518521e-05, 'epoch': 1.2412028150991683, 'step': 1940}\n",
      "{'loss': 0.2755749702453613, 'learning_rate': 1.4484848484848486e-05, 'epoch': 1.2476007677543186, 'step': 1950}\n",
      "{'loss': 0.10899721980094909, 'learning_rate': 1.4451178451178452e-05, 'epoch': 1.253998720409469, 'step': 1960}\n",
      "{'loss': 0.1820923924446106, 'learning_rate': 1.4417508417508419e-05, 'epoch': 1.2603966730646192, 'step': 1970}\n",
      "{'loss': 0.16234519481658935, 'learning_rate': 1.4383838383838384e-05, 'epoch': 1.2667946257197698, 'step': 1980}\n",
      "{'loss': 0.19568407237529756, 'learning_rate': 1.4350168350168351e-05, 'epoch': 1.27319257837492, 'step': 1990}\n",
      "{'loss': 0.1309371843934059, 'learning_rate': 1.4316498316498317e-05, 'epoch': 1.2795905310300704, 'step': 2000}\n",
      "{'loss': 0.17607949078083038, 'learning_rate': 1.4282828282828285e-05, 'epoch': 1.2859884836852207, 'step': 2010}\n",
      "{'loss': 0.16210477203130721, 'learning_rate': 1.424915824915825e-05, 'epoch': 1.292386436340371, 'step': 2020}\n",
      "{'loss': 0.1419723391532898, 'learning_rate': 1.4215488215488216e-05, 'epoch': 1.2987843889955215, 'step': 2030}\n",
      "{'loss': 0.18155937194824218, 'learning_rate': 1.4181818181818183e-05, 'epoch': 1.3051823416506718, 'step': 2040}\n",
      "{'loss': 0.19232459217309952, 'learning_rate': 1.4148148148148148e-05, 'epoch': 1.3115802943058221, 'step': 2050}\n",
      "{'loss': 0.20127791166305542, 'learning_rate': 1.4114478114478116e-05, 'epoch': 1.3179782469609724, 'step': 2060}\n",
      "{'loss': 0.15442492812871933, 'learning_rate': 1.4080808080808081e-05, 'epoch': 1.3243761996161227, 'step': 2070}\n",
      "{'loss': 0.120758917927742, 'learning_rate': 1.404713804713805e-05, 'epoch': 1.3307741522712733, 'step': 2080}\n",
      "{'loss': 0.11375035792589187, 'learning_rate': 1.4013468013468015e-05, 'epoch': 1.3371721049264236, 'step': 2090}\n",
      "{'loss': 0.07751624882221222, 'learning_rate': 1.397979797979798e-05, 'epoch': 1.3435700575815739, 'step': 2100}\n",
      "{'loss': 0.155682572722435, 'learning_rate': 1.3946127946127947e-05, 'epoch': 1.3499680102367242, 'step': 2110}\n",
      "{'loss': 0.14043150395154952, 'learning_rate': 1.3912457912457913e-05, 'epoch': 1.3563659628918745, 'step': 2120}\n",
      "{'loss': 0.22504920065402984, 'learning_rate': 1.387878787878788e-05, 'epoch': 1.362763915547025, 'step': 2130}\n",
      "{'loss': 0.24051471501588823, 'learning_rate': 1.3845117845117845e-05, 'epoch': 1.3691618682021753, 'step': 2140}\n",
      "{'loss': 0.23038415163755416, 'learning_rate': 1.3811447811447814e-05, 'epoch': 1.3755598208573256, 'step': 2150}\n",
      "{'loss': 0.23413684964179993, 'learning_rate': 1.377777777777778e-05, 'epoch': 1.381957773512476, 'step': 2160}\n",
      "{'loss': 0.17201227247714995, 'learning_rate': 1.3744107744107745e-05, 'epoch': 1.3883557261676263, 'step': 2170}\n",
      "{'loss': 0.10524817556142807, 'learning_rate': 1.3710437710437712e-05, 'epoch': 1.3947536788227768, 'step': 2180}\n",
      "{'loss': 0.1586904525756836, 'learning_rate': 1.3676767676767677e-05, 'epoch': 1.401151631477927, 'step': 2190}\n",
      "{'loss': 0.21159951090812684, 'learning_rate': 1.3643097643097644e-05, 'epoch': 1.4075495841330774, 'step': 2200}\n",
      "{'loss': 0.17708949744701385, 'learning_rate': 1.360942760942761e-05, 'epoch': 1.4139475367882277, 'step': 2210}\n",
      "{'loss': 0.1166828840970993, 'learning_rate': 1.3575757575757578e-05, 'epoch': 1.420345489443378, 'step': 2220}\n",
      "{'loss': 0.24497248232364655, 'learning_rate': 1.3542087542087544e-05, 'epoch': 1.4267434420985285, 'step': 2230}\n",
      "{'loss': 0.27355661541223525, 'learning_rate': 1.3508417508417509e-05, 'epoch': 1.4331413947536789, 'step': 2240}\n",
      "{'loss': 0.30495172142982485, 'learning_rate': 1.3474747474747476e-05, 'epoch': 1.4395393474088292, 'step': 2250}\n",
      "{'loss': 0.19388152211904525, 'learning_rate': 1.3441077441077441e-05, 'epoch': 1.4459373000639795, 'step': 2260}\n",
      "{'loss': 0.10783693790435792, 'learning_rate': 1.3407407407407408e-05, 'epoch': 1.4523352527191298, 'step': 2270}\n",
      "{'loss': 0.17277667671442032, 'learning_rate': 1.3373737373737374e-05, 'epoch': 1.4587332053742803, 'step': 2280}\n",
      "{'loss': 0.14293176531791688, 'learning_rate': 1.3340067340067343e-05, 'epoch': 1.4651311580294306, 'step': 2290}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1970289707183838, 'learning_rate': 1.3306397306397308e-05, 'epoch': 1.471529110684581, 'step': 2300}\n",
      "{'loss': 0.13032741695642472, 'learning_rate': 1.3272727272727275e-05, 'epoch': 1.4779270633397312, 'step': 2310}\n",
      "{'loss': 0.23026261925697328, 'learning_rate': 1.323905723905724e-05, 'epoch': 1.4843250159948815, 'step': 2320}\n",
      "{'loss': 0.14627012312412263, 'learning_rate': 1.3205387205387206e-05, 'epoch': 1.490722968650032, 'step': 2330}\n",
      "{'loss': 0.17240799963474274, 'learning_rate': 1.3171717171717173e-05, 'epoch': 1.4971209213051824, 'step': 2340}\n",
      "{'loss': 0.1505471259355545, 'learning_rate': 1.3138047138047138e-05, 'epoch': 1.5035188739603327, 'step': 2350}\n",
      "{'loss': 0.1913965255022049, 'learning_rate': 1.3104377104377107e-05, 'epoch': 1.5099168266154832, 'step': 2360}\n",
      "{'loss': 0.1654383882880211, 'learning_rate': 1.3070707070707072e-05, 'epoch': 1.5163147792706333, 'step': 2370}\n",
      "{'loss': 0.18454862534999847, 'learning_rate': 1.303703703703704e-05, 'epoch': 1.5227127319257838, 'step': 2380}\n",
      "{'loss': 0.13087759017944336, 'learning_rate': 1.3003367003367005e-05, 'epoch': 1.5291106845809341, 'step': 2390}\n",
      "{'loss': 0.1542524591088295, 'learning_rate': 1.296969696969697e-05, 'epoch': 1.5355086372360844, 'step': 2400}\n",
      "{'loss': 0.21641849279403685, 'learning_rate': 1.2936026936026937e-05, 'epoch': 1.541906589891235, 'step': 2410}\n",
      "{'loss': 0.20312236994504929, 'learning_rate': 1.2902356902356902e-05, 'epoch': 1.548304542546385, 'step': 2420}\n",
      "{'loss': 0.10317314714193344, 'learning_rate': 1.2868686868686871e-05, 'epoch': 1.5547024952015356, 'step': 2430}\n",
      "{'loss': 0.09764927178621292, 'learning_rate': 1.2835016835016837e-05, 'epoch': 1.561100447856686, 'step': 2440}\n",
      "{'loss': 0.3032684996724129, 'learning_rate': 1.2801346801346804e-05, 'epoch': 1.5674984005118362, 'step': 2450}\n",
      "{'loss': 0.17055683434009553, 'learning_rate': 1.2767676767676769e-05, 'epoch': 1.5738963531669867, 'step': 2460}\n",
      "{'loss': 0.17317892462015153, 'learning_rate': 1.2734006734006734e-05, 'epoch': 1.5802943058221368, 'step': 2470}\n",
      "{'loss': 0.18452388048171997, 'learning_rate': 1.2700336700336701e-05, 'epoch': 1.5866922584772873, 'step': 2480}\n",
      "{'loss': 0.27260725796222685, 'learning_rate': 1.2666666666666667e-05, 'epoch': 1.5930902111324377, 'step': 2490}\n",
      "{'loss': 0.11580686420202255, 'learning_rate': 1.2632996632996634e-05, 'epoch': 1.599488163787588, 'step': 2500}\n",
      "{'loss': 0.13016328513622283, 'learning_rate': 1.2599326599326601e-05, 'epoch': 1.6058861164427385, 'step': 2510}\n",
      "{'loss': 0.2385251358151436, 'learning_rate': 1.2565656565656568e-05, 'epoch': 1.6122840690978886, 'step': 2520}\n",
      "{'loss': 0.16756472438573838, 'learning_rate': 1.2531986531986533e-05, 'epoch': 1.618682021753039, 'step': 2530}\n",
      "{'loss': 0.18590577989816665, 'learning_rate': 1.2498316498316499e-05, 'epoch': 1.6250799744081894, 'step': 2540}\n",
      "{'loss': 0.15566953867673874, 'learning_rate': 1.2464646464646466e-05, 'epoch': 1.6314779270633397, 'step': 2550}\n",
      "{'loss': 0.07634854316711426, 'learning_rate': 1.2430976430976431e-05, 'epoch': 1.6378758797184902, 'step': 2560}\n",
      "{'loss': 0.2699560895562172, 'learning_rate': 1.2397306397306398e-05, 'epoch': 1.6442738323736403, 'step': 2570}\n",
      "{'loss': 0.18599361926317215, 'learning_rate': 1.2363636363636364e-05, 'epoch': 1.6506717850287909, 'step': 2580}\n",
      "{'loss': 0.28428826481103897, 'learning_rate': 1.2329966329966332e-05, 'epoch': 1.6570697376839412, 'step': 2590}\n",
      "{'loss': 0.1436494141817093, 'learning_rate': 1.2296296296296298e-05, 'epoch': 1.6634676903390915, 'step': 2600}\n",
      "{'loss': 0.14821331053972245, 'learning_rate': 1.2262626262626263e-05, 'epoch': 1.669865642994242, 'step': 2610}\n",
      "{'loss': 0.28343279510736463, 'learning_rate': 1.222895622895623e-05, 'epoch': 1.676263595649392, 'step': 2620}\n",
      "{'loss': 0.15983969271183013, 'learning_rate': 1.2195286195286195e-05, 'epoch': 1.6826615483045426, 'step': 2630}\n",
      "{'loss': 0.12880089282989501, 'learning_rate': 1.2161616161616162e-05, 'epoch': 1.689059500959693, 'step': 2640}\n",
      "{'loss': 0.1941496729850769, 'learning_rate': 1.2127946127946128e-05, 'epoch': 1.6954574536148432, 'step': 2650}\n",
      "{'loss': 0.09003940373659133, 'learning_rate': 1.2094276094276097e-05, 'epoch': 1.7018554062699938, 'step': 2660}\n",
      "{'loss': 0.13924432098865508, 'learning_rate': 1.2060606060606062e-05, 'epoch': 1.7082533589251438, 'step': 2670}\n",
      "{'loss': 0.17976855784654616, 'learning_rate': 1.2026936026936027e-05, 'epoch': 1.7146513115802944, 'step': 2680}\n",
      "{'loss': 0.2868188574910164, 'learning_rate': 1.1993265993265994e-05, 'epoch': 1.7210492642354447, 'step': 2690}\n",
      "{'loss': 0.2084581509232521, 'learning_rate': 1.195959595959596e-05, 'epoch': 1.727447216890595, 'step': 2700}\n",
      "{'loss': 0.1308036267757416, 'learning_rate': 1.1925925925925927e-05, 'epoch': 1.7338451695457455, 'step': 2710}\n",
      "{'loss': 0.10806365013122558, 'learning_rate': 1.1892255892255892e-05, 'epoch': 1.7402431222008956, 'step': 2720}\n",
      "{'loss': 0.24680066704750062, 'learning_rate': 1.1858585858585861e-05, 'epoch': 1.7466410748560461, 'step': 2730}\n",
      "{'loss': 0.12848704308271408, 'learning_rate': 1.1824915824915826e-05, 'epoch': 1.7530390275111964, 'step': 2740}\n",
      "{'loss': 0.1981121063232422, 'learning_rate': 1.1791245791245792e-05, 'epoch': 1.7594369801663468, 'step': 2750}\n",
      "{'loss': 0.0476686418056488, 'learning_rate': 1.1757575757575759e-05, 'epoch': 1.7658349328214973, 'step': 2760}\n",
      "{'loss': 0.21608301848173142, 'learning_rate': 1.1723905723905724e-05, 'epoch': 1.7722328854766474, 'step': 2770}\n",
      "{'loss': 0.0516886442899704, 'learning_rate': 1.1690235690235691e-05, 'epoch': 1.778630838131798, 'step': 2780}\n",
      "{'loss': 0.23385369628667832, 'learning_rate': 1.1656565656565656e-05, 'epoch': 1.7850287907869482, 'step': 2790}\n",
      "{'loss': 0.21427906751632692, 'learning_rate': 1.1622895622895625e-05, 'epoch': 1.7914267434420985, 'step': 2800}\n",
      "{'loss': 0.20387343019247056, 'learning_rate': 1.158922558922559e-05, 'epoch': 1.797824696097249, 'step': 2810}\n",
      "{'loss': 0.11269174516201019, 'learning_rate': 1.1555555555555556e-05, 'epoch': 1.8042226487523991, 'step': 2820}\n",
      "{'loss': 0.14332410991191863, 'learning_rate': 1.1521885521885523e-05, 'epoch': 1.8106206014075497, 'step': 2830}\n",
      "{'loss': 0.171482589840889, 'learning_rate': 1.1488215488215488e-05, 'epoch': 1.8170185540627, 'step': 2840}\n",
      "{'loss': 0.19744413048028947, 'learning_rate': 1.1454545454545455e-05, 'epoch': 1.8234165067178503, 'step': 2850}\n",
      "{'loss': 0.05949762761592865, 'learning_rate': 1.142087542087542e-05, 'epoch': 1.8298144593730008, 'step': 2860}\n",
      "{'loss': 0.13062732964754104, 'learning_rate': 1.138720538720539e-05, 'epoch': 1.8362124120281509, 'step': 2870}\n",
      "{'loss': 0.12901808470487594, 'learning_rate': 1.1353535353535355e-05, 'epoch': 1.8426103646833014, 'step': 2880}\n",
      "{'loss': 0.12475948184728622, 'learning_rate': 1.1319865319865322e-05, 'epoch': 1.8490083173384517, 'step': 2890}\n",
      "{'loss': 0.10118180066347122, 'learning_rate': 1.1286195286195287e-05, 'epoch': 1.855406269993602, 'step': 2900}\n",
      "{'loss': 0.2084355741739273, 'learning_rate': 1.1252525252525253e-05, 'epoch': 1.8618042226487526, 'step': 2910}\n",
      "{'loss': 0.2761350065469742, 'learning_rate': 1.121885521885522e-05, 'epoch': 1.8682021753039026, 'step': 2920}\n",
      "{'loss': 0.16274821013212204, 'learning_rate': 1.1185185185185185e-05, 'epoch': 1.8746001279590532, 'step': 2930}\n",
      "{'loss': 0.22330392003059388, 'learning_rate': 1.1151515151515154e-05, 'epoch': 1.8809980806142035, 'step': 2940}\n",
      "{'loss': 0.19963857531547546, 'learning_rate': 1.111784511784512e-05, 'epoch': 1.8873960332693538, 'step': 2950}\n",
      "{'loss': 0.07583089172840118, 'learning_rate': 1.1084175084175086e-05, 'epoch': 1.8937939859245043, 'step': 2960}\n",
      "{'loss': 0.07006362825632095, 'learning_rate': 1.1050505050505052e-05, 'epoch': 1.9001919385796544, 'step': 2970}\n",
      "{'loss': 0.18419713526964188, 'learning_rate': 1.1016835016835017e-05, 'epoch': 1.906589891234805, 'step': 2980}\n",
      "{'loss': 0.16449467688798905, 'learning_rate': 1.0983164983164984e-05, 'epoch': 1.9129878438899552, 'step': 2990}\n",
      "{'loss': 0.19758045077323913, 'learning_rate': 1.094949494949495e-05, 'epoch': 1.9193857965451055, 'step': 3000}\n",
      "{'loss': 0.2211338073015213, 'learning_rate': 1.0915824915824918e-05, 'epoch': 1.925783749200256, 'step': 3010}\n",
      "{'loss': 0.10558114349842071, 'learning_rate': 1.0882154882154884e-05, 'epoch': 1.9321817018554062, 'step': 3020}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.13295522779226304, 'learning_rate': 1.084848484848485e-05, 'epoch': 1.9385796545105567, 'step': 3030}\n",
      "{'loss': 0.254815936088562, 'learning_rate': 1.0814814814814816e-05, 'epoch': 1.944977607165707, 'step': 3040}\n",
      "{'loss': 0.17257849872112274, 'learning_rate': 1.0781144781144781e-05, 'epoch': 1.9513755598208573, 'step': 3050}\n",
      "{'loss': 0.25620238184928895, 'learning_rate': 1.0747474747474748e-05, 'epoch': 1.9577735124760078, 'step': 3060}\n",
      "{'loss': 0.13200246393680573, 'learning_rate': 1.0713804713804714e-05, 'epoch': 1.964171465131158, 'step': 3070}\n",
      "{'loss': 0.1859428808093071, 'learning_rate': 1.0680134680134683e-05, 'epoch': 1.9705694177863085, 'step': 3080}\n",
      "{'loss': 0.122044138610363, 'learning_rate': 1.0646464646464648e-05, 'epoch': 1.9769673704414588, 'step': 3090}\n",
      "{'loss': 0.16623858362436295, 'learning_rate': 1.0612794612794615e-05, 'epoch': 1.983365323096609, 'step': 3100}\n",
      "{'loss': 0.14927822947502137, 'learning_rate': 1.057912457912458e-05, 'epoch': 1.9897632757517596, 'step': 3110}\n",
      "{'loss': 0.1281729981303215, 'learning_rate': 1.0545454545454546e-05, 'epoch': 1.9961612284069097, 'step': 3120}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e73d4311ca458db204b9228b9b99dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1563.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.22688088119029998, 'learning_rate': 1.0511784511784513e-05, 'epoch': 2.00255918106206, 'step': 3130}\n",
      "{'loss': 0.08465697318315506, 'learning_rate': 1.0478114478114478e-05, 'epoch': 2.0089571337172103, 'step': 3140}\n",
      "{'loss': 0.04573826193809509, 'learning_rate': 1.0444444444444445e-05, 'epoch': 2.015355086372361, 'step': 3150}\n",
      "{'loss': 0.11550106704235077, 'learning_rate': 1.041077441077441e-05, 'epoch': 2.0217530390275114, 'step': 3160}\n",
      "{'loss': 0.07424029856920242, 'learning_rate': 1.037710437710438e-05, 'epoch': 2.0281509916826614, 'step': 3170}\n",
      "{'loss': 0.04768117666244507, 'learning_rate': 1.0343434343434345e-05, 'epoch': 2.034548944337812, 'step': 3180}\n",
      "{'loss': 0.04327450692653656, 'learning_rate': 1.030976430976431e-05, 'epoch': 2.040946896992962, 'step': 3190}\n",
      "{'loss': 0.056641629338264464, 'learning_rate': 1.0276094276094277e-05, 'epoch': 2.0473448496481126, 'step': 3200}\n",
      "{'loss': 0.1299564242362976, 'learning_rate': 1.0242424242424242e-05, 'epoch': 2.053742802303263, 'step': 3210}\n",
      "{'loss': 0.03525798171758652, 'learning_rate': 1.020875420875421e-05, 'epoch': 2.060140754958413, 'step': 3220}\n",
      "{'loss': 0.05365554988384247, 'learning_rate': 1.0175084175084175e-05, 'epoch': 2.0665387076135637, 'step': 3230}\n",
      "{'loss': 0.05975492149591446, 'learning_rate': 1.0141414141414144e-05, 'epoch': 2.072936660268714, 'step': 3240}\n",
      "{'loss': 0.12381814271211625, 'learning_rate': 1.0107744107744109e-05, 'epoch': 2.0793346129238643, 'step': 3250}\n",
      "{'loss': 0.08954705893993378, 'learning_rate': 1.0074074074074074e-05, 'epoch': 2.085732565579015, 'step': 3260}\n",
      "{'loss': 0.15703179091215133, 'learning_rate': 1.0040404040404041e-05, 'epoch': 2.092130518234165, 'step': 3270}\n",
      "{'loss': 0.08695947229862214, 'learning_rate': 1.0006734006734007e-05, 'epoch': 2.0985284708893155, 'step': 3280}\n",
      "{'loss': 0.07908379584550858, 'learning_rate': 9.973063973063974e-06, 'epoch': 2.1049264235444656, 'step': 3290}\n",
      "{'loss': 0.020956917107105254, 'learning_rate': 9.939393939393939e-06, 'epoch': 2.111324376199616, 'step': 3300}\n",
      "{'loss': 0.06796707510948181, 'learning_rate': 9.905723905723906e-06, 'epoch': 2.1177223288547666, 'step': 3310}\n",
      "{'loss': 0.06213173568248749, 'learning_rate': 9.872053872053873e-06, 'epoch': 2.1241202815099167, 'step': 3320}\n",
      "{'loss': 0.04517068713903427, 'learning_rate': 9.838383838383839e-06, 'epoch': 2.1305182341650672, 'step': 3330}\n",
      "{'loss': 0.09850267171859742, 'learning_rate': 9.804713804713806e-06, 'epoch': 2.1369161868202173, 'step': 3340}\n",
      "{'loss': 0.08289882838726044, 'learning_rate': 9.771043771043773e-06, 'epoch': 2.143314139475368, 'step': 3350}\n",
      "{'loss': 0.08269420564174652, 'learning_rate': 9.737373737373738e-06, 'epoch': 2.1497120921305184, 'step': 3360}\n",
      "{'loss': 0.10361937284469605, 'learning_rate': 9.703703703703703e-06, 'epoch': 2.1561100447856685, 'step': 3370}\n",
      "{'loss': 0.06469497084617615, 'learning_rate': 9.67003367003367e-06, 'epoch': 2.162507997440819, 'step': 3380}\n",
      "{'loss': 0.0901098057627678, 'learning_rate': 9.636363636363638e-06, 'epoch': 2.168905950095969, 'step': 3390}\n",
      "{'loss': 0.2164618968963623, 'learning_rate': 9.602693602693603e-06, 'epoch': 2.1753039027511196, 'step': 3400}\n",
      "{'loss': 0.10311452597379685, 'learning_rate': 9.56902356902357e-06, 'epoch': 2.18170185540627, 'step': 3410}\n",
      "{'loss': 0.04703845679759979, 'learning_rate': 9.535353535353537e-06, 'epoch': 2.1880998080614202, 'step': 3420}\n",
      "{'loss': 0.040472652018070224, 'learning_rate': 9.501683501683502e-06, 'epoch': 2.1944977607165708, 'step': 3430}\n",
      "{'loss': 0.07261764854192734, 'learning_rate': 9.468013468013468e-06, 'epoch': 2.200895713371721, 'step': 3440}\n",
      "{'loss': 0.1012135922908783, 'learning_rate': 9.434343434343435e-06, 'epoch': 2.2072936660268714, 'step': 3450}\n",
      "{'loss': 0.02964104413986206, 'learning_rate': 9.400673400673402e-06, 'epoch': 2.213691618682022, 'step': 3460}\n",
      "{'loss': 0.07947025150060653, 'learning_rate': 9.367003367003367e-06, 'epoch': 2.220089571337172, 'step': 3470}\n",
      "{'loss': 0.08822550177574158, 'learning_rate': 9.333333333333334e-06, 'epoch': 2.2264875239923225, 'step': 3480}\n",
      "{'loss': 0.1534462869167328, 'learning_rate': 9.299663299663301e-06, 'epoch': 2.2328854766474726, 'step': 3490}\n",
      "{'loss': 0.023951974511146546, 'learning_rate': 9.265993265993267e-06, 'epoch': 2.239283429302623, 'step': 3500}\n",
      "{'loss': 0.11166193187236786, 'learning_rate': 9.232323232323232e-06, 'epoch': 2.2456813819577737, 'step': 3510}\n",
      "{'loss': 0.07735144793987274, 'learning_rate': 9.1986531986532e-06, 'epoch': 2.2520793346129238, 'step': 3520}\n",
      "{'loss': 0.03527352511882782, 'learning_rate': 9.164983164983166e-06, 'epoch': 2.2584772872680743, 'step': 3530}\n",
      "{'loss': 0.0115976482629776, 'learning_rate': 9.131313131313132e-06, 'epoch': 2.2648752399232244, 'step': 3540}\n",
      "{'loss': 0.08088716268539428, 'learning_rate': 9.097643097643099e-06, 'epoch': 2.271273192578375, 'step': 3550}\n",
      "{'loss': 0.06279202401638032, 'learning_rate': 9.063973063973066e-06, 'epoch': 2.2776711452335254, 'step': 3560}\n",
      "{'loss': 0.13687311112880707, 'learning_rate': 9.030303030303031e-06, 'epoch': 2.2840690978886755, 'step': 3570}\n",
      "{'loss': 0.0559276282787323, 'learning_rate': 8.996632996632996e-06, 'epoch': 2.290467050543826, 'step': 3580}\n",
      "{'loss': 0.08422520458698272, 'learning_rate': 8.962962962962963e-06, 'epoch': 2.2968650031989766, 'step': 3590}\n",
      "{'loss': 0.08611057996749878, 'learning_rate': 8.92929292929293e-06, 'epoch': 2.3032629558541267, 'step': 3600}\n",
      "{'loss': 0.011051800847053529, 'learning_rate': 8.895622895622896e-06, 'epoch': 2.309660908509277, 'step': 3610}\n",
      "{'loss': 0.12494045794010163, 'learning_rate': 8.861952861952863e-06, 'epoch': 2.3160588611644273, 'step': 3620}\n",
      "{'loss': 0.140614153444767, 'learning_rate': 8.82828282828283e-06, 'epoch': 2.322456813819578, 'step': 3630}\n",
      "{'loss': 0.0975208729505539, 'learning_rate': 8.794612794612795e-06, 'epoch': 2.328854766474728, 'step': 3640}\n",
      "{'loss': 0.07144442200660706, 'learning_rate': 8.760942760942762e-06, 'epoch': 2.3352527191298784, 'step': 3650}\n",
      "{'loss': 0.061829566955566406, 'learning_rate': 8.727272727272728e-06, 'epoch': 2.341650671785029, 'step': 3660}\n",
      "{'loss': 0.03858371376991272, 'learning_rate': 8.693602693602695e-06, 'epoch': 2.348048624440179, 'step': 3670}\n",
      "{'loss': 0.03470012545585632, 'learning_rate': 8.65993265993266e-06, 'epoch': 2.3544465770953296, 'step': 3680}\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    logger.critical(\"Start to train\")\n",
    "    train_res = trainer.train()\n",
    "    \n",
    "    if dataset_args['val_size'] != 0:\n",
    "        logger.critical(\"Start to evaluate\")\n",
    "        eval_res = trainer.evaluate()\n",
    "    \n",
    "    logger.critical(\"Start to test\")\n",
    "    test_res = trainer.predict(test_dataset)\n",
    "    \n",
    "    # è®°å½•å®žéªŒå‚æ•°\n",
    "    mlflow.set_tags(mlflow_tags)\n",
    "    mlflow.log_params(train_params)\n",
    "\n",
    "    # è®°å½•æµ‹è¯•çš„è¯„ä¼°æŒ‡æ ‡\n",
    "    mlflow.log_metric(\"train_loss\", train_res.training_loss)\n",
    "    if dataset_args['val_size'] != 0:\n",
    "        mlflow.log_metrics(eval_res)\n",
    "    mlflow.log_metrics({k.replace('eval', 'test'): v for k, v in test_res.metrics.items()})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.critical(\"Save the model and config\")\n",
    "trainer.save_model()\n",
    "tokenizer.save_vocabulary(training_args.output_dir)\n",
    "logger.critical(\"Experiment Finnished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
